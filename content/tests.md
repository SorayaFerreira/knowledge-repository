---
title: tests
description: Conte√∫dos sobre Verifica√ß√£o, Valida√ß√£o e Teste de Software
pubDate: Mar 18 2025
tags:
  - Testes
  - Playwright
  - VVT
---
<img width=100% src="https://capsule-render.vercel.app/api?type=waving&color=ff5733&height=120&section=header"/>

# Sum√°rio
- [Tipos de Testes](#tipos-de-testes)
- [Verifica√ß√£o X Valida√ß√£o](#verifica√ß√£o--valida√ß√£o)
- [Playwright](#playwright)

# Anota√ß√µes das Aulas üìù
**Anota√ß√µes da Disciplina de Verifica√ß√£o, Valida√ß√£o e Teste de Software**  

## REVIS√ÉO, INSPE√á√ÉO E CONCEITOS

* Aprova√ß√£o de PR sem coment√°rio √© uma revis√£o inv√°lida. Precisa haver evid√™ncias de que vc revisou aquilo.  
* **Verifica√ß√£o:** analisar se o produto de software est√° sendo desenvolvido da maneira correta. *Are we building the software right?*  
* **Valida√ß√£o:** analisar se o que est√° sendo desenvolvido est√° correto, de acordo com o que foi solicitado pelo cliente que atende √†s necessidades dos usu√°rios. *Are we building the right software?*  
* **Teste:** √© o conjunto de t√©cnicas utilizado num processo que ratifica se as funcionalidades e o sistema como um todo est√£o funcionando consoante o esperado, levando em conta o contexto. Economia, confian√ßa, seguran√ßa, neg√≥cio. √â imposs√≠vel testar exaustivamente,  
* *A **revis√£o √©** um processo de leitura de um artefato de software. O objetivo √© que aquele artefato tenha qualidade suficiente para implementarmos a pr√≥xima etapa.* Realizamos verifica√ß√£o e valida√ß√£o **est√°tica** de artefatos de software. Ela garante qualidade e manutenibilidade. Tamb√©m promove a transpar√™ncia de conhecimento entre os membros da equipe, evitando ‚Äúilhas de conhecimento‚Äù. A revis√£o deve ser feita por duas pessoas. E o objetivo dela n√£o √© o de corrigir nada, mas de encontrar problemas e atribu√≠-los ao dev. *Um produto √© examinado por stakeholders, que fornecem coment√°rios e aprova√ß√µes.*  
* **Inspe√ß√£o:** t√©cnica mais formal do que a revis√£o t√©cnica, com objetivo principal a identifica√ß√£o e a remo√ß√£o de defeitos.   
* √â legal entender os algoritmos de mesclagem de branches do GIT.  
* Tipos: walkthrough; inspe√ß√µes de software e Revis√£o.  
* **Walkthrough:** reuni√£o informal para avaliar um produto. Objetivo √© comunicar ou receber aprova√ß√£o. S√£o √∫teis para requisitos e modelos. Tem um conjunto de pap√©is na reuni√£o. Tem que ser pragm√°tica, objetiva. O desenvolvedor guia os presentes atrav√©s do produto. *√â o mais flex√≠vel e informal do tr√™s.* Tem l√≠der, autor, revisor, escriv√£o.  
* **Inspe√ß√£o:** √© mais rigorosa e formal. Deve ter plano de medi√ß√£o para coletar m√©tricas. Tem pap√©is tamb√©m na reuni√£o. Quando um detalhe √© apontado mais de uma vez, ele deixa de ser uma discrep√¢ncia e se torna um defeito. Toma menos de uma hora por defeito, que deve ser removido. *Precisa haver um profissional experiente em Engenharia de Software. Tem autor, moderador e inspetor.*  
* **Heur√≠stica**: lista fundamentada de t√©cnicas que nos guiam em algo.  
* **Discrep√¢ncia:** desvio de expectativa, falta de clareza em algo, pode ser uma falta de revis√£o em fases anteriores, √© uma issue que voc√™ classifica com enhancement.  
* **Norma IEEE 830:** para verificar a conformidade do c√≥digo seguindo os requisitos. Omiss√£o, ambiguidade, inconsist√™ncia, fato incorreto, informa√ß√£o estranha, discrep√¢ncia.  
* **Defeito:** impede o funcionamento correto.  
* **T√©cnicas para detec√ß√£o de defeitos: ad-hoc** (faz do jeito que te d√° na cabe√ßa), **check-list** (lista de quest√µes que os inspetores devem responder, com respostas sim/n√£o. Bom para **novatos**), t√©cnicas de leitura.  
* **Software com qualidade:** √© uma solu√ß√£o que atende √†s necessidades dos interessados, causando sua satisfa√ß√£o. Conformidade com requisitos e satisfa√ß√£o do cliente.  
* **Depura√ß√£o:** visualiza uma consequ√™ncia n√£o previs√≠vel do teste. Apenas identifica a localiza√ß√£o do erro, mas n√£o aponta a falha em si.  
* **Estrat√©gias de Teste:**   
  * **Pir√¢mide de teste:** teste unit√°rio \> teste de integra√ß√£o \> teste de UI \> teste de Jornada de usu√°rio.  
  * **√Årvore de testes:** an√°lise est√°tica \> testes unit√°rios/integra√ß√£o \> testes de snapshot \> testes E2E. Evita a cria√ß√£o de testes sens√≠veis, que quebram quando h√° uma mudan√ßa em algum componente. Flex√≠vel e resiliente.  
  * **Modelo de queijo sui√ßo:** cada fatia de queijo √© uma camada do sistema. As camadas s√£o imperfeitas, com buracos. Por√©m, se as camadas forem sobrepostas, alguns buracos ficam cobertos, outros ficam ainda expostos. A meta do modelo sui√ßo √© impedir que uma falha passe por esse buraco que restou. Teste automatizado \> teste manual \> valida√ß√£o do cliente \> mitigando o erro. Servi√ßo \> BFF (Backend for Frontend) \> UI \> End to end.  
* A base de nossa estrat√©gia √© ser eficaz e sistem√°tica. Escrever testes certos e permitir que qualquer dev consiga chegar √† mesma su√≠te de testes.  
* **Paradoxo do pesticida:** um mesmo tipo de veneno n√£o √© capaz de matar todas as pragas poss√≠veis numa lavoura.  
* **Stubs:** usado em testes de integra√ß√£o. √â uma pseudo-implementa√ß√£o de determinadas especifica√ß√µes. *Dubl√™ de resposta.*  
* **Drivers:** opera√ß√µes que automatizam testes de acordo com casos de teste. *Dubl√™ de chamador.*  
* **Teste de Sistema:** recupera√ß√£o \> seguran√ßa \> stress \> desempenho.  
* **Reteste:**   
  * **regress√£o: a**plica a cada nova vers√£o do software ou a cada ciclo, todos os testes que j√° foram aplicados nas vers√µes anteriores.  
  * **aceita√ß√£o:** foco nos requisitos, testes funcionais, o sistema satisfaz ou n√£o seus crit√©rios de aceita√ß√£o.  
  * **fuma√ßa:** √© uma estrat√©gia de integra√ß√£o incremental. O sistema √© reconstru√≠do com novos componentes incorporados e √© exercitado diariamente.

## CASOS DE TESTE

* Um **incremento** √© algo funcional que vai para produ√ß√£o. Os testes devem ser sempre rastre√°veis com os requisitos.  
* Nosso curso √© chamado *Engenharia,* porque √© sistem√°tica e quantific√°vel e depende muito de processo.  
* O teste funcional √© **caixa-preta.**  
* Se n√£o foi encontrado falhas no teste, podemos dizer que o software √© de alta qualidade, ou o teste √© de baixa qualidade. Isso vai depender de: n√≠vel de conhecimento, tipo do teste sendo feito, fase do projeto, maturidade da equipe, n√≠vel de cobertura.  
* O plano no caso de teste vai at√© o resultado esperado, apenas. N√£o tem resultado obtido, isso n√£o fica no plano de teste.  
* A execu√ß√£o do teste precisa ter uma ordem l√≥gica. Gestos entram em testes mobile.  
* Um registro s√≥ √© v√°lido se ele tem uma evid√™ncia, como um print, um log, um v√≠deo, etc.  
* H√° informa√ß√µes *sens√≠veis ao contexto,* como as aplica√ß√µes de clima.  
* **Bateria de testes \== Rodada**: conjunto de casos de teste para uma determinada entrega. √â relativo ao objetivo de uma sprint.  
* A prioridade dos casos de teste √© definida de acordo com a estrat√©gia de teste.  
* **Procedimento:** √© quando eu testo duas coisas ligadas, mas seguindo uma ordem. Conjunto de a√ß√µes para testar algo.  
* **su√≠te:** √© um conjunto de cen√°rios de teste.  
* **Caso de teste:** entrada, restri√ß√µes para sua execu√ß√£o, resultado esperado, comportamento esperado.  
* **Elementos:** roteiro de teste, crit√©rios de cobertura dos testes, bateria de testes, incidentes de teste (issue, bug).  
* **Testes de integra√ß√£o:**  
  * Bing-bang: construir tudo separado e integrar s√≥ no final. Dificulta o encontro de defeitos.  
  * Bottom-up: m√≥dulos de n√≠vel mais baixo, ou seja, que n√£o dependem um do outro. M√≥dulo s√≥ √© integrado quando os dependentes j√° foram integrados e testados. N√£o √© necess√°rio escrever stubs.  
  * Top-down: m√≥dulos de n√≠vel mais alto, verificando inicialmente os m√≥dulos com mais import√¢ncia precisa de bons e v√°rios stubs.

## ESTRAT√âGIAS DE TESTE

* Na sprint 0, voc√™ precisa definir uma estrat√©gia de testes, de verifica√ß√£o e de valida√ß√£o, analisando o documento de requisitos, a complexidade do dom√≠nio e o n√≠vel de maturidade da equipe. Essa estrat√©gia precisa ser eficaz e sistem√°tica.  
* **fitness function/fun√ß√£o objetivo**: √©   
* A **unidade de um teste** consiste tanto no componente sendo testado, quanto no c√≥digo do teste em si.  
* **Mockar:** √© fazer **stubs e drivers**.   
* Tanto fluxos principais quanto fluxos arriscados precisam receber teste de sistema.  
* **Smoke-test:** definir casos de teste priorit√°rios numa situa√ß√£o de urg√™ncia com o m√≠nimo para garantir qualidade.  
* **Teste de regress√£o:** √© quando voltamos nas sprints anteriores e recuperamos os testes feitos, a fim de garantir que testes feitos anteriormente continuam funcionando.  
    
* **AN√ÅLISE DO VALOR LIMITE**  
* Um grande n√∫mero de erros tende a ocorrer nos limites do dom√≠nio de entrada inv√©s de no centro.  
    
* **GRAFO DE CAUSA-EFEITO**: √© aquele diagrama escama de peixe.
* **Crit√©rio** (n√£o t√©cnica) necess√°rio quando se deseja testar combina√ß√µes de entradas.  
* Utiliza √°rvores de decis√£o.  
* Se um requisito √© muito simples, n√£o precisa utilizar um recurso de infraestrutura.

## TESTES \- PR√ÅTICA

* A **estrat√©gia de qualidade** abrange a estrat√©gia de testes.  
* √â importante modelar visualmente a estrat√©gia de testes para que o time tenha total compreens√£o.  
* N√£o adianta querer automatizar todos os testes poss√≠veis.  
* O **Modelo do Trof√©u** √© outro modelo de estrat√©gia de testes s√≥ que mais voltado para o ecossistema javascript.  
* Existe um milh√£o de ferramentas de testes automatizados. N√£o pode priorizar apenas as ferramentas que voc√™ domina. Tem que dar prefer√™ncia praquilo que resolve o problema.  
* Tamb√©m n√£o adianta pensar nas melhores tecnologias, padr√µes, modelos etc, se n√≥s n√£o levarmos em considera√ß√£o os **3 Ps ‚Äì Pessoas, Processos e Produto**.  
* O Selenium √© antig√£o e mais manual. O Cypress permite automatizar melhor algumas coisas, ele √© voltado para testes end-to-end.  
* Todo elemento do HTML est√° estruturado numa √°rvore chamada DOM. √â com ele que a gente interage. O ID √© o filtro para busca mais r√°pido, √© quase instant√¢neo.

## GERENCIAMENTO DE DEFEITOS

* No NES, eles t√™m percebido que, se o time n√£o entende a arquitetura muito bem, eles n√£o conseguem fazer testes unit√°rios e de integra√ß√£o.  
* Como a gente prioriza os testes unit√°rios? R.: tem que ter entendimento do neg√≥cio, do que √© a entrega, os crit√©rios de teste, o objetivo da sprint.  
* N√£o podemos negligenciar os testes unit√°rios dentro da sprint.  
* A gente precisa saber gerenciar os defeitos.  
* Na sprint review voc√™ precisa dar credibilidade que aquele incremento tem valor.  
* O defeito est√° no meio, entre o erro e a falha. O termo gen√©rico √© bug, mas √© poss√≠vel classificar entre erro, defeito e falha. Quando voc√™ comete um erro, isso produz um defeito. Quando esse defeito surgir, n√≥s temos uma falha.  
* Para n√≥s da engenharia de software √© o impacto que concretiza as consequ√™ncias de se fazer algo errado.  
* √â importante fazer os iniciantes do time sentirem a dor do valor do impacto dele. √â importante expor as pessoas aos defeitos.  
* H√° 3 tipos de defeitos:  
  * Faltantes: falta total ou parcial de um requisito.  
  * Errado: o requisito foi implementado incorretamente.  
  * Acr√©scimo: comportamento ou elemento que foi implementado, mas n√£o estava especificado no requisito. Se quiser sugerir, coloque como enhancement  
* Voc√™ tem que encontrar defeito, sim, no final da sprint, sobretudo se for sprint especial. Sempre desconfie daquilo que voc√™ est√° entregando.  
* O pr√≥prio github, via issues, j√° √© um tipo de rastreamento de defeitos.  
* **Recomenda√ß√µes para o relato de defeitos:**  
  * Resumir: descrever o defeito resumidamente.  
  * Precis√£o: antes de reclamar, certifique-se de que √© um desvio de comportamento mesmo, e n√£o uma falha de conhecimento.  
  * Neutralizar: nada de humor, piadinha, nada. N√£o ser prolixo.  
  * Generalizar: complementando a descri√ß√£o com repert√≥rio, apontando poss√≠veis impactos futuros.  
  * Reproduzir: tem que ser reproduz√≠vel para ter qualidade.  
  * Evidenciar: dar evid√™ncias do defeito, seja com prints, com v√≠deo, logs etc.  
  * Revisar: revisar a descri√ß√£o, tratando ele como um documento de projeto, s√©rio, grave.  
* Sin√¥nimos de bug: incidente, erro, falha, defeito  
* **Testes Cont√≠nuos:** tem o fito de n√£o deixar o teste apenas para o final. Tem uma vertente que busca automatizar tudo que √© pass√≠vel de ser automatizado, o que n√£o estiver, deve ser muito bem justificado e assinado e aprovado por quem concordou com isso. Oferece maior efici√™ncia e qualidade de implementa√ß√£o, redu√ß√£o de desconex√µes entre membros de equipes de DevOps. Detec√ß√£o e corre√ß√£o r√°pida de erros. Feedback cont√≠nuo e melhoria antecipada. Aprimorar a experi√™ncia de usu√°rio. Redu√ß√£o de custos com interrup√ß√µes.   
* **Metodologias de teste cont√≠nuo:** shift-left, teste de unidade, testes de integra√ß√£o e mensagens, teste shift-right, teste de fuma√ßa (smoke testing).  
* **Teste A/B:** √© uma estrat√©gia de teste em produ√ß√£o bem confi√°vel.  
* **Teste de pico (ou teste de estresse):** √© realmente deixar o sistema sendo utilizado para voc√™ identificar os gargalos.  
* **Pr√°ticas recomendadas para testes em produ√ß√£o**: criar um dataset de dados sint√©ticos, nomear dados de teste, evitar uso de dados reais por causa da LGPD (elemento de triangula√ß√£o), t√©cnicas de prote√ß√£o, credenciais de teste para ter controle, testar sob baixa carga (momentos de pouco acesso do sistema),   
* N√£o adianta nada as ferramentas serem boas se voc√™s n√£o s√£o bons profissionais.  


## PROJETANDO PARA TESTABILIDADE

* Serve para saber se algo √© test√°vel.  
* √â o grau em que um sistema de software ou uma unidade sob teste suporta seu pr√≥prio teste. √â a capacidade de um artefato de software (sistema, m√≥dulo, requisitos ou documento de design)  
* Ter alta testabilidade significa ter facilidade em identificar falhas.  
* Baixa testabilidade: mais esfor√ßo para testar, menos testes por per√≠odo de tempo; menos chances de encontrar defeitos.  
* √â imposs√≠vel estabelecer crit√©rios se os requisitos n√£o estiverem muito bem definidos.  
* A testabilidade est√° mais ligada aos requisitos.  
* Testes flaky: √© um teste inst√°vel, √†s vezes funciona, √†s vezes n√£o.  
* DfT \- Design for Testability: projetar para testabilidade.  
* Teste sistem√°tico: novatos devem conseguem entender o que acontece num teste, utilizar e fazer manuten√ß√£o no teste. Se um novato n√£o conseguir isso com facilidade, o teste n√£o foi sistem√°tico.  
* Observabilidade: √© a facilidade de ver o que est√° ocorrendo num componente. √â algo importante para a testabilidade.  
* Um bom desenvolvedor sabe fazer bons testes.  
* Assertiva √© para comparar o resultado real com o resultado esperado.  
* O **dom√≠nio** √© o cora√ß√£o da aplica√ß√£o.  
* C√≥digo de coisas externas √† aplica√ß√£o, como APIs externas, s√£o coisas da infraestrutura.  
* Os artefatos precisam ser preparados para serem testados.  
* Qualquer artefato que est√° ligado ao software deve ser test√°vel.  
* A testabilidade est√° diretamente ligada √† clareza dos requisitos  
* ‚ÄúSe temos c√≥digo dif√≠cil de testar, provavelmente ele n√£o ser√° testado.‚Äù  
* Os testes s√£o os primeiros clientes do c√≥digo que voc√™ escreve.


# Tipos de Testes ‚öóÔ∏èüß™
A seguir, apresento os tipos de teste mencionados nas fontes (prof. Awdren), com uma explica√ß√£o simplificada de suas caracter√≠sticas e exemplos.

> **Teste Funcional (ou Caixa Preta / Caixa Fechada)**
*   Caracter√≠sticas: Baseia-se na especifica√ß√£o dos requisitos do software, sem considerar os detalhes internos da implementa√ß√£o. Ele aborda o software de um ponto de vista macrosc√≥pico, focado em verificar se as fun√ß√µes est√£o sendo executadas corretamente sob a perspectiva do usu√°rio.
*   T√©cnicas Comuns: Para otimizar a quantidade de testes, utiliza-se o Particionamento de Equival√™ncia, que divide o dom√≠nio de entrada em subdom√≠nios, e a An√°lise do Valor Limite, que foca nos valores extremos das entradas, onde os erros tendem a ocorrer com mais frequ√™ncia. Quando h√° intera√ß√µes entre m√∫ltiplas vari√°veis de entrada, podem ser empregados Grafo de Causa-Efeito ou Tabelas de Decis√£o para testar combina√ß√µes l√≥gicas. Existe tamb√©m a t√©cnica Baseada em Erros, que pressup√µe intuitivamente os tipos prov√°veis de erros.

> **Teste Estrutural (ou Caixa Branca / Caixa Transparente)**
*   Caracter√≠sticas: Diferente do teste funcional, este tipo de teste √© baseado na estrutura interna do c√≥digo-fonte e exige conhecimento da implementa√ß√£o. Seu objetivo √© exercitar o maior n√∫mero poss√≠vel de caminhos, ramos e instru√ß√µes do programa, identificando trechos de c√≥digo n√£o exercitados e complementando os testes baseados em requisitos.
*   Crit√©rios de Cobertura: S√£o utilizadas m√©tricas como Cobertura de Linhas (executar todas as instru√ß√µes), Cobertura de Ramos (garantir que cada ramo de decis√£o seja executado), Cobertura de Condi√ß√µes/Decis√µes (avaliar cada decis√£o como verdadeira e falsa) e Cobertura de Caminhos (executar todas as sequ√™ncias poss√≠veis de execu√ß√£o). Um crit√©rio mais rigoroso, usado em sistemas cr√≠ticos, √© o MC/DC (Modified Condition/Decision Coverage), que assegura que cada condi√ß√£o em uma decis√£o afete isoladamente o resultado final.

> **Teste de Unidade (Unit Test)**
*   Caracter√≠sticas: √â a fase em que se testam as menores unidades de software desenvolvidas, como m√©todos ou pequenos trechos de c√≥digo, de forma isolada. √â um teste r√°pido, f√°cil de controlar e escrever, proporcionando feedback imediato aos desenvolvedores. O objetivo √© encontrar falhas de funcionamento dentro de uma pequena parte do sistema, independentemente do todo.

> **Teste de Integra√ß√£o:**
*   Caracter√≠sticas: Ap√≥s as unidades serem testadas separadamente, este teste as avalia de forma integrada, focando na interface entre as unidades e na intera√ß√£o do c√≥digo com partes externas. Para auxiliar, s√£o utilizados Stubs (pseudo-implementa√ß√µes que simulam respostas de componentes ainda n√£o prontos) e Drivers (simulam chamadas de m√≥dulos que ainda n√£o existem). Existem estrat√©gias como *Big-bang* (integrar tudo no final), *Bottom-up* (integrar m√≥dulos de baixo n√≠vel primeiro) e *Top-down* (integrar m√≥dulos de alto n√≠vel primeiro).

> **Teste de Sistema:**
*   Caracter√≠sticas: Investiga o funcionamento da aplica√ß√£o como um todo, incluindo a execu√ß√£o dos fluxos dos casos de uso e a integra√ß√£o com o ambiente operacional (similar ao de produ√ß√£o). O objetivo √© executar o sistema do ponto de vista do usu√°rio final, buscando falhas em caracter√≠sticas funcionais (regras de neg√≥cio) e n√£o-funcionais (como usabilidade, seguran√ßa, efici√™ncia).
*   Tipos Espec√≠ficos: Inclui testes de Recupera√ß√£o (verifica a capacidade de recupera√ß√£o do produto ap√≥s falhas), Seguran√ßa (verifica os mecanismos de prote√ß√£o), Stress (executa o sistema com recursos anormais) e Desempenho (avalia o desempenho do software integrado ao sistema).

> **Teste de Aceita√ß√£o:**
*   Caracter√≠sticas: √â um teste funcional realizado pelos usu√°rios finais para demonstrar a conformidade do software com os requisitos definidos pelo cliente. Envolve treinamento, documenta√ß√£o e empacotamento.
*   Subtipos: Podem ser Teste Alfa (executado na instala√ß√£o do desenvolvedor pelo cliente) e Teste Beta (executado na instala√ß√£o de um ou mais clientes pelo usu√°rio final).

> **Teste de Regress√£o:**
*   Caracter√≠sticas: Consiste em reaplicar todos os testes que j√° foram executados em vers√µes ou ciclos anteriores do sistema, a cada nova vers√£o ou modifica√ß√£o do software. √â crucial para reduzir "efeitos colaterais" e garantir que mudan√ßas ou corre√ß√µes n√£o introduziram novos defeitos ou quebraram funcionalidades existentes.

> **Teste de Fuma√ßa (Smoke Testing):**
*   Caracter√≠sticas: Uma verifica√ß√£o superficial e r√°pida para detectar as falhas mais cr√≠ticas em um sistema, realizada logo ap√≥s uma nova build. √â um teste r√°pido e barato, √∫til para verificar se as funcionalidades essenciais est√£o funcionando antes de testes mais aprofundados.

> **Teste E2E (End-to-End) / Jornada de Usu√°rio:**
*   Caracter√≠sticas: Foca na execu√ß√£o do sistema na perspectiva do usu√°rio final, simulando uma jornada completa de uso. Abrange desde o front-end at√© o back-end, garantindo que as funcionalidades operem corretamente em cen√°rios reais. Esses testes podem ser caros para manuten√ß√£o. Em aplicativos m√≥veis, s√£o grandes testes de integra√ß√£o que buscam simular o mais pr√≥ximo da produ√ß√£o.

> **Teste de Usabilidade (User eXperience - UX):**
*   Caracter√≠sticas: Concentra-se em avaliar se a aplica√ß√£o √© f√°cil de usar e satisfat√≥ria para o usu√°rio final. Envolve a an√°lise de conte√∫do, funcionalidades, navegabilidade, design e o feedback de usu√°rios reais para capturar suas expectativas e percep√ß√µes ap√≥s o uso. Falhas de usabilidade s√£o as que mais afetam a percep√ß√£o de qualidade por usu√°rios m√≥veis.

> **Teste de Seguran√ßa:**
*   Caracter√≠sticas: Verifica se os mecanismos de prote√ß√£o do sistema funcionam corretamente, protegendo-o contra uso indevido ou intrus√µes. Em aplica√ß√µes m√≥veis, isso inclui garantir que o aplicativo atenda aos requisitos de seguran√ßa definidos pelos *stakeholders*, cuidando do armazenamento de dados, provedores de conte√∫do, uso de permiss√µes e valida√ß√£o de dados do usu√°rio.

> **Teste de Desempenho:**
*   Caracter√≠sticas: Avalia o desempenho do software quando integrado ao sistema, verificando sua capacidade de atender a requisitos n√£o-funcionais como velocidade, tempo de resposta, quantidade de downloads, velocidade do processador e capacidade de armazenamento. Geralmente est√° associado ao teste de Stress.

> **Teste de Compatibilidade:**
*   Caracter√≠sticas: Verifica se a aplica√ß√£o m√≥vel roda corretamente em todos os dispositivos e sistemas operacionais alvo. √â crucial devido √† fragmenta√ß√£o, que √© a grande diversidade de dispositivos e vers√µes de SO no mercado. Uma matriz de compatibilidade √© frequentemente usada para planejar e documentar essa verifica√ß√£o.

> **Teste de Estabilidade:**
*   Caracter√≠sticas: Avalia a capacidade do aplicativo de funcionar de forma cont√≠nua e confi√°vel sob diferentes condi√ß√µes de uso, sem travamentos, falhas ou degrada√ß√£o de desempenho. Foca na resist√™ncia do aplicativo diante de longas sess√µes, mudan√ßas de rede, uso intenso de recursos do dispositivo e integra√ß√µes com servi√ßos externos.

> **Teste de Conectividade:**
*   Caracter√≠sticas: Tem como objetivo testar o acesso a todos os componentes essenciais para que a aplica√ß√£o m√≥vel fa√ßa uso apropriado do contexto em que estiver inserida, especialmente em rela√ß√£o √† infraestrutura de rede (telecomunica√ß√µes).

> **Teste de Certifica√ß√£o:**
*   Caracter√≠sticas: Verifica se a aplica√ß√£o m√≥vel atende a todos os padr√µes estabelecidos pelas lojas de aplicativos (como Google Play, App Store e Windows Store) onde ser√° distribu√≠da. Os crit√©rios s√£o aplicados quando a aplica√ß√£o j√° foi desenvolvida e ser√° submetida para publica√ß√£o.

> **Testar em Produ√ß√£o:**
*   Caracter√≠sticas: Uma fase complementar de testes realizada no ambiente real de produ√ß√£o para obter resultados mais precisos. Aumenta a confian√ßa da equipe de que os usu√°rios experimentar√£o a mesma funcionalidade verificada.
*   Tipos Espec√≠ficos: Inclui Monitoramento Cont√≠nuo (estabilidade, tempo de resposta), Monitoramento de Aplica√ß√µes (RUM - Real User Monitoring, e monitoramento sint√©tico), Acompanhamento em Tempo Real (verificar transa√ß√µes em cada camada). Tamb√©m s√£o feitos Testes A/B (para obter feedback de usu√°rios sobre diferentes vers√µes) e Teste de Pico (avalia desempenho sob carga extrema).


Importante mencionar que nenhuma t√©cnica de teste isolada pode encontrar todos os *bugs* (paradoxo do pesticida) e que o teste exaustivo √© imposs√≠vel. Portanto, √© crucial saber o que testar, priorizar e combinar diferentes t√©cnicas de forma eficaz e sistem√°tica para maximizar a detec√ß√£o de defeitos e otimizar o custo do processo. O contexto do software (aplicativo m√≥vel, web, sistema cr√≠tico) tamb√©m desempenha um papel fundamental na defini√ß√£o dos casos de teste.

# Erro üÜö Falha üÜö Defeito

Os termos "falha", "defeito" e "erro" muitas vezes s√£o usados de forma intercambi√°vel, mas possuem nuances importantes no contexto de testes de software.

Aqui est√° um resumo das diferen√ßas e rela√ß√µes, com base nas informa√ß√µes fornecidas:

> Defeito (Bug/Falha/Erro):
    *   As ferramentas de gest√£o de projetos frequentemente agrupam "Defeitos, Erros e Falhas" sob o termo "Defeitos" ou "Bugs".
    *   Um defeito √© definido como um problema no c√≥digo ou no design do software que impede seu funcionamento correto.
    *   Ele ocorre quando o software n√£o atende aos requisitos especificados ou gera um comportamento incorreto devido a falhas na implementa√ß√£o.
    *   Defeitos s√£o encontrados atrav√©s da execu√ß√£o de testes, durante o uso do sistema em produ√ß√£o ou at√© por acidente.
    *   Ap√≥s a revela√ß√£o da presen√ßa de um erro, o defeito √© o que precisa ser encontrado e corrigido.

> Falha:
    *   A "falha" √© mencionada como um dos termos sin√¥nimos para "defeito" ou "bug".
    *   O objetivo do teste √© "revelar a presen√ßa de FALHAS" no programa ou sistema.
    *   √â importante notar que "n√£o h√° garantia que todo incidente seja uma falha, pois ainda precisa ser analisado". Isso sugere que uma falha √© a manifesta√ß√£o observ√°vel de um problema (defeito) durante a execu√ß√£o.
    *   As fontes tamb√©m mencionam "falhas na implementa√ß√£o" como causa de um defeito.

> Erro:
    *   Assim como "falha", "erro" √© listado como um sin√¥nimo para "defeito" ou "bug".
    *   No contexto de depura√ß√£o, a presen√ßa do erro √© o que √© revelado pelo teste, e √© a partir dessa revela√ß√£o que o defeito deve ser encontrado e corrigido. Isso sugere que o "erro" pode ser a condi√ß√£o que se manifesta e indica a exist√™ncia de um defeito subjacente.
    *   Um exemplo pr√°tico √© o do foguete Ariane 5, que foi destru√≠do devido a um "erro de navega√ß√£o" causado por um "equ√≠voco", indicando o erro como a causa do desvio de comportamento.

H√° uma distin√ß√£o clara entre Discrep√¢ncia e Defeito:

*   Discrep√¢ncia: Refere-se a qualquer desvio entre o comportamento esperado e o comportamento real de um sistema, mas n√£o necessariamente indica um erro no software. Pode ser resultado de uma interpreta√ß√£o amb√≠gua dos requisitos, uma mudan√ßa nas expectativas do usu√°rio ou at√© uma caracter√≠stica do ambiente de execu√ß√£o. Por exemplo, o sistema exibe uma mensagem de alerta ao excluir um item, mas o cliente esperava uma solicita√ß√£o de confirma√ß√£o.
*   Defeito: √â um problema no c√≥digo ou no design do software que impede seu funcionamento correto. Um defeito ocorre quando o software n√£o atende aos requisitos especificados ou gera um comportamento incorreto devido a falhas na implementa√ß√£o. Um exemplo √© quando o sistema permite excluir um item, mas n√£o remove corretamente os registros associados, causando inconsist√™ncias nos dados.

Ou seja, um erro humano leva a um defeito no c√≥digo/design, que por sua vez pode causar uma falha no comportamento do sistema.

# Verifica√ß√£o ‚ùé Valida√ß√£o
A diferen√ßa entre Verifica√ß√£o e Valida√ß√£o √© a ordem das duas √∫ltimas palavras nas frases a seguir:
> ‚Äî Verifica√ß√£o: "Are we building the product right?"
> ‚Äî Valida√ß√£o: "Are we building the right product?"

# Playwright
- Serve para testes de automa√ß√£o, sobretudo em browsers e mobile.
- Tem suporte para v√°rias linguagens de programa√ß√£o.
- A documenta√ß√£o √© organizada e intuitiva: https://playwright.dev/docs/intro
- Pode ser usado para web scraping.
- √â preciso ter um projeto com node.js (npm init) antes de tentar instalar o playwright.

# try...catch üÜö Results

- O `results.ts` √© uma abordagem diferente para tratamentos de erros e exce√ß√µes. 
- Nesse caso, estamos utilizando TypeScript, mas tal abordagem pode surgir em v√°rias linguagens diferentes, como o Golang, por exemplo. 
- A ideia do results.ts gera algo muito elegante, que √© melhor detalhado no arquivo [js_ts.ipnynb](typescript.ipynb).

```javascript
try {
    nonExistentFunction();

} catch (error) {
    console.error(error);

} finally {
    // padr√µes executados independente de ter entrado no try ou no catch.
}
```

- O `catch` informa o qu√™ fazer se for lan√ßada uma exce√ß√£o durante a execu√ß√£o do try.
- √â poss√≠vel aninhar blocos try-catch.

```javascript
try {
  throw new TypeError("oops");
} catch ({ name, message }) {
  console.log(name); // "TypeError"
  console.log(message); // "oops"
}
```

# Para um Plano de Testes ‚úèÔ∏èüìÑ
> Tudo que √© necess√°rio para cria√ß√£o de um Plano de Testes, conforme Awdren:

## 1. Contextualiza√ß√£o do Projeto
- Qual √© o objetivo principal do sistema?
- Quem s√£o os usu√°rios finais desse sistema?
- Esse m√≥dulo faz parte de qual etapa do processo de neg√≥cio?

## 2. Descri√ß√£o do M√≥dulo a ser Testado
- Qual √© a funcionalidade principal do m√≥dulo?
-  Quais s√£o as entradas esperadas e sa√≠das produzidas?
- Existem pr√©-condi√ß√µes ou depend√™ncias com outros m√≥dulos ou servi√ßos externos?
- H√° alguma interface com o usu√°rio? Se sim, qual √© o fluxo esperado?

## 3. Requisitos e Regras de Neg√≥cio
- Quais s√£o os principais requisitos funcionais do m√≥dulo?
- Existem regras de neg√≥cio cr√≠ticas que precisam de aten√ß√£o especial?
- Quais s√£o os cen√°rios que obrigatoriamente devem ser testados?
- H√° casos de uso priorit√°rios ou que envolvem l√≥gica sens√≠vel?

## 4. Crit√©rios de Aceita√ß√£o e Qualidade
- O que caracteriza que o m√≥dulo est√° funcionando corretamente?
- Existem crit√©rios n√£o funcionais a serem considerados (ex: desempenho, seguran√ßa,
usabilidade)?
- Quais s√£o os crit√©rios m√≠nimos de aceita√ß√£o para que o m√≥dulo seja considerado
pronto?

## 5. Riscos e √Åreas Cr√≠ticas
- Quais partes do m√≥dulo s√£o mais propensas a falhas ou exigem mais aten√ß√£o?
- H√° altera√ß√µes recentes ou funcionalidades novas que precisam ser priorizadas nos
testes?
- Existem dados sens√≠veis ou integra√ß√µes externas a serem validadas?

## 6. Ambiente e Dados de Teste
- Em qual ambiente o time de QA realizar√° os testes (homologa√ß√£o, staging, etc.)?
- Que tipos de dados estar√£o dispon√≠veis para os testes (reais, fict√≠cios,
anonimizados)?
- Existem configura√ß√µes espec√≠ficas ou permiss√µes que o time de QA precisa
conhecer?

## 7. Automa√ß√£o e Suporte ao QA
- J√° existem testes automatizados para este m√≥dulo? Se sim, quais?
- O time de desenvolvimento poder√° fornecer mocks, scripts ou dados de apoio para
os testes?
- H√° logs, dashboards ou ferramentas auxiliares dispon√≠veis para acompanhamento? 

## 8. Acordos de Comunica√ß√£o e Feedback
- Quem ser√° o ponto de contato para d√∫vidas ou alinhamentos?
- Como ser√° feito o registro, triagem e prioriza√ß√£o de defeitos encontrados?
- Qual o prazo estimado para a execu√ß√£o dos testes e para o retorno das an√°lises?

<img width=100% src="https://capsule-render.vercel.app/api?type=waving&color=ff5733&height=120&section=footer"/>
